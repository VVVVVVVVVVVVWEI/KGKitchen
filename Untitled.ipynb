{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the spacy and regex implementation for extracting food from recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import library, loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import regex\n",
    "import json\n",
    "# probably other dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./recipe/recipe.json\",\"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "nlp =  spacy.load('en_core_web_lg')\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "from spacy.lang.en import LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES\n",
    "from spacy.tokenizer import Tokenizer\n",
    "Tokenizer = Tokenizer(nlp.vocab)\n",
    "Lemmatizer = Lemmatizer(LEMMA_INDEX, LEMMA_EXC, LEMMA_RULES)\n",
    "# import en_core_seb_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 1/2 d/d NUM CD\n",
      "cup cup xxx NOUN NN\n",
      "confectioners confectioner xxxx NOUN NNS\n",
      "' ' ' PART POS\n",
      "sugar sugar xxxx NOUN NN\n",
      "for for xxx ADP IN\n",
      "decoration decoration xxxx NOUN NN\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(data[0][\"food_ingredients\"][-1])\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.shape_, token.pos_, token.tag_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(text):\n",
    "    return nlp(\" \".join(list(map(lambda x: x.lemma_,nlp(text)))))\n",
    "\n",
    "# test= nlp('1 1/4 cups butter')\n",
    "# for token in test:\n",
    "#     if token.tag_ == \"NNS\":\n",
    "#         import pdb\n",
    "#         pdb.set_trace()\n",
    "#         token = Tokenizer(Lemmatizer(token.text, \"NOUN\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= nlp('1 1/4 cups butter')\n",
    "t = lemmatizer('1 1/4 cups butter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 1/4 cup butter'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    1/2\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " cup confectioners' sugar for decoration</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load('en_core_web_lg')\n",
    "dog = nlp.vocab[\"dog\"]\n",
    "cat = nlp.vocab[\"cat\"]\n",
    "apple = nlp.vocab[\"apple\"]\n",
    "orange = nlp.vocab[\"orange\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog.similarity(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting up entity class and entity list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entities = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class entity:\n",
    "    def __init__(self, recipe):\n",
    "        self.recipe = recipe\n",
    "        self.ingredient = [x for x in recipe[\"food_ingredients\"]]\n",
    "        self.number = [0.0 for x in recipe[\"food_ingredients\"]]\n",
    "        self.unit = [\"TBD\" for x in recipe[\"food_ingredients\"]]\n",
    "        self.entities = [\"TBD\" for x in recipe[\"food_ingredients\"]]\n",
    "#         self.failure\n",
    "#         self.recipe_triple = []\n",
    "    def get_nlpres(self, nlp_output, index):\n",
    "        if not nlp_output:\n",
    "            self.number[index]=\"TBD\"\n",
    "            self.unit[index] = \"TBD\"\n",
    "            self.entities[index] = \"TBD\"\n",
    "#             print(\"\")\n",
    "            return\n",
    "        res = 0.0\n",
    "        for v in nlp_output:\n",
    "            if v[1] != 'CARDINAL' and v[1] != \"QUANTITY\":\n",
    "#                 print(v)\n",
    "                pass\n",
    "            elif v[1] == \"CARDINAL\":\n",
    "                vals = v[0].split()\n",
    "#                 res = 0.0\n",
    "                for _ in vals:\n",
    "                    try:\n",
    "                        res+=eval(_)\n",
    "                    except:\n",
    "                        break\n",
    "                self.number[index]=res\n",
    "        \n",
    "#                 self.unit.append(\"TBD\")\n",
    "#                 self.entities.append(\"TBD\")\n",
    "            else:\n",
    "                vals = v[0].split()\n",
    "#                 res = 0.0\n",
    "                for _ in vals:\n",
    "                    try:\n",
    "                        res += eval(_)\n",
    "                    except:\n",
    "                        self.unit[index] = _\n",
    "                        break\n",
    "                self.number[index] = res\n",
    "#                 self.entities.append(\"TBD\")\n",
    "            #TBD as default since cannot find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "an_entity = entity(data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entities = list(map(lambda x:entity(x), data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3828"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = an_entity.ingredient\n",
    "for i, _ in enumerate(w):\n",
    "    tmp = lemmatizer(_)\n",
    "    an_entity.ingredient[i] = str(tmp)\n",
    "#     print(tmp)\n",
    "    recog = [(d.text, d.label_) for d in tmp.ents]\n",
    "#     print(recog)\n",
    "    an_entity.get_nlpres(recog, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.25, 0.6666666666666666, 1.0, 2.0, 0.125, 0.5, 2.0, 0.5]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "an_entity.number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 1/4 cup butter',\n",
       " '2/3 cup white sugar',\n",
       " '1 teaspoon vanilla extract',\n",
       " '2 cup all - purpose flour',\n",
       " '1/8 teaspoon salt',\n",
       " '1/2 cup unsweetened cocoa powder',\n",
       " '2 cup chop pecan',\n",
       " \"1/2 cup confectioner ' sugar for decoration\"]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "an_entity.ingredient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run nlp for all_entities and saving as step1 pickle file, in this step, we resolve numbers and unit, item was filled by \"TBD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in all_entities:\n",
    "    words = e.ingredient\n",
    "    for i, w in enumerate(words):\n",
    "        tmp = lemmatizer(w)\n",
    "        e.ingredient[i] = str(tmp)\n",
    "        for t in tmp:\n",
    "            t = t.lemma_\n",
    "        recog = [(d.text, d.label_) for d in tmp.ents]\n",
    "        e.get_nlpres(recog, i)\n",
    "    \n",
    "        # automaticly find\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not have a valid number, discard\n",
    "for _, l in enumerate(all_entities):\n",
    "    for i, n in enumerate(l.number):\n",
    "#         print(i)\n",
    "        if n == \"TBD\":\n",
    "#             print(i)\n",
    "            l.ingredient[i] = \"not valid\"\n",
    "            l.unit[i] = \"not valid\"\n",
    "            l.entities[i] = \"not valid\"\n",
    "            l.number[i] = \"not valid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"first_step_number.pkl\", \"wb\") as p:\n",
    "    pickle.dump(all_entities, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload pickled file, start with items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_all_entities = pickle.load(open(\"first_step_number.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3828"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loaded_all_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.25, 0.6666666666666666, 1.0, 2.0, 0.125, 0.5, 2.0, 0.5]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_all_entities[0].number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cup',\n",
       " 'cup',\n",
       " 'cup',\n",
       " 'TBD',\n",
       " 'cup',\n",
       " 'TBD',\n",
       " 'TBD',\n",
       " 'teaspoon',\n",
       " 'teaspoon',\n",
       " 'teaspoon',\n",
       " 'teaspoon',\n",
       " 'teaspoon']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_all_entities[5].unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 1/4 cup butter , soften',\n",
       " '1 1/4 cup white sugar',\n",
       " '3/4 cup light corn syrup',\n",
       " '2 small egg',\n",
       " '3 cup all - purpose flour',\n",
       " '1 1/2 teaspoon baking powder',\n",
       " '1 teaspoon baking soda',\n",
       " '1/2 teaspoon salt',\n",
       " '2 teaspoon ground cinnamon',\n",
       " '2 teaspoon ground clove',\n",
       " '1 teaspoon ground ginger',\n",
       " '1/4 teaspoon ground black pepper']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_all_entities[5].ingredient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statical result about first step entity recoginition number\n",
    "cnt = 0\n",
    "for l in loaded_all_entities:\n",
    "    for n in l.number:\n",
    "        if n == \"TBD\":\n",
    "            cnt += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "971"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "for l in loaded_all_entities:\n",
    "    for n in l.number:\n",
    "        if n == \"not valid\":\n",
    "            cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cup', 'cup', 'teaspoon', 'cup', 'teaspoon', 'cup', 'cup', 'TBD']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_all_entities[0].unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in test:\n",
    "    print(token.text, token.lemma_, token.shape_, token.pos_, token.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9365"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "for l in loaded_all_entities:\n",
    "    for n in l.unit:\n",
    "        if n == \"TBD\":\n",
    "            cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33456"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "for l in loaded_all_entities:\n",
    "    for n in l.unit:\n",
    "        cnt+=1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27991989478718315"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9365/33456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = '3 cup all - purpose flour'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3 d NUM CD\n",
      "cup cup xxx NOUN NN\n",
      "all all xxx DET DT\n",
      "- - - PUNCT HYPH\n",
      "purpose purpose xxxx NOUN NN\n",
      "flour flour xxxx NOUN NN\n"
     ]
    }
   ],
   "source": [
    "for token in nlp(test_sentence):\n",
    "    print(token.text, token.lemma_, token.shape_, token.pos_, token.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence2 = \"3 small egg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3 d NUM CD\n",
      "small small xxxx ADJ JJ\n",
      "egg egg xxx NOUN NN\n"
     ]
    }
   ],
   "source": [
    "for token in nlp(test_sentence2):\n",
    "    print(token.text, token.lemma_, token.shape_, token.pos_, token.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence3 = \"2 teaspoon ground cinnamon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2 d NUM CD\n",
      "teaspoon teaspoon xxxx NOUN NN\n",
      "ground ground xxxx NOUN NN\n",
      "cinnamon cinnamon xxxx NOUN NN\n"
     ]
    }
   ],
   "source": [
    "for token in nlp(test_sentence3):\n",
    "    print(token.text, token.lemma_, token.shape_, token.pos_, token.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence4 = '1 1/4 cup butter , soften'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 d NUM CD\n",
      "1/4 1/4 d/d NUM CD\n",
      "cup cup xxx NOUN NN\n",
      "butter butter xxxx NOUN NN\n",
      ", , , PUNCT ,\n",
      "soften soften xxxx VERB VB\n"
     ]
    }
   ],
   "source": [
    "for token in nlp(test_sentence4):\n",
    "    print(token.text, token.lemma_, token.shape_, token.pos_, token.tag_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only keep NN, remove things already in unit, change \"TBD\" in unit to default unit(\"ge\"), val = \"DEFAULT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in loaded_all_entities:\n",
    "    for i,u in enumerate(l.unit):\n",
    "        if u == \"TBD\":\n",
    "            l.unit[i] = \"DEFAULT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9365"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "for l in loaded_all_entities:\n",
    "    for n in l.unit:\n",
    "        if n == \"DEFAULT\":\n",
    "            cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in loaded_all_entities:\n",
    "    for i, n in enumerate(l.number):\n",
    "        if l.ingredient[i] != \"not valid\":\n",
    "            tmp = nlp(l.ingredient[i])\n",
    "            res = []\n",
    "            for token in tmp:\n",
    "                if token.tag_ == \",\":\n",
    "                    break\n",
    "                if token.tag_ == \"NN\" or token.tag_ == \"JJ\":\n",
    "                    if token.text != l.unit[i]:\n",
    "                        res.append(token.text)\n",
    "            l.entities[i] = \" \".join(res)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 1/2 d/d NUM CD\n",
      "cup cup xxx NOUN NN\n",
      "confectioners confectioner xxxx NOUN NNS\n",
      "' ' ' PART POS\n",
      "sugar sugar xxxx NOUN NN\n",
      "for for xxx ADP IN\n",
      "decoration decoration xxxx NOUN NN\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(data[0][\"food_ingredients\"][-1])\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.shape_, token.pos_, token.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['butter',\n",
       " 'white sugar',\n",
       " 'vanilla extract',\n",
       " 'purpose flour',\n",
       " 'salt',\n",
       " 'unsweetened cocoa powder',\n",
       " 'chop pecan',\n",
       " 'cup confectioner sugar decoration']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_all_entities[0].entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cup', 'cup', 'teaspoon', 'cup', 'teaspoon', 'cup', 'cup', 'DEFAULT']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_all_entities[0].unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 1/4 cup butter',\n",
       " '2/3 cup white sugar',\n",
       " '1 teaspoon vanilla extract',\n",
       " '2 cup all - purpose flour',\n",
       " '1/8 teaspoon salt',\n",
       " '1/2 cup unsweetened cocoa powder',\n",
       " '2 cup chop pecan',\n",
       " \"1/2 cup confectioner ' sugar for decoration\"]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_all_entities[0].ingredient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 1/2 d/d NUM CD\n",
      "cup cup xxx NOUN NN\n",
      "unsweetened unsweetened xxxx ADJ JJ\n",
      "cocoa cocoa xxxx NOUN NN\n",
      "powder powder xxxx NOUN NN\n"
     ]
    }
   ],
   "source": [
    "t = '1/2 cup unsweetened cocoa powder'\n",
    "for token in nlp(t):\n",
    "    print(token.text, token.lemma_, token.shape_, token.pos_, token.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "for l in loaded_all_entities:\n",
    "    for e in l.entities:\n",
    "        if e == \"TBD\":\n",
    "            cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['butter',\n",
       " 'white sugar',\n",
       " 'light corn syrup',\n",
       " 'small egg',\n",
       " 'purpose flour',\n",
       " 'teaspoon baking powder',\n",
       " 'teaspoon baking soda',\n",
       " 'salt',\n",
       " 'ground cinnamon',\n",
       " 'ground clove',\n",
       " 'ground ginger',\n",
       " 'ground black pepper']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_all_entities[5].entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 1/4 cup butter , soften',\n",
       " '1 1/4 cup white sugar',\n",
       " '3/4 cup light corn syrup',\n",
       " '2 small egg',\n",
       " '3 cup all - purpose flour',\n",
       " '1 1/2 teaspoon baking powder',\n",
       " '1 teaspoon baking soda',\n",
       " '1/2 teaspoon salt',\n",
       " '2 teaspoon ground cinnamon',\n",
       " '2 teaspoon ground clove',\n",
       " '1 teaspoon ground ginger',\n",
       " '1/4 teaspoon ground black pepper']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_all_entities[5].ingredient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving result to pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"extraction.pkl\", \"wb\") as p:\n",
    "    pickle.dump(loaded_all_entities, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### saving new result to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "for l in loaded_all_entities:\n",
    "    output = l.recipe\n",
    "    output[\"extraction_results\"] = []\n",
    "    for i, n in enumerate(l.number):\n",
    "        output[\"extraction_results\"].append((l.number[i], l.unit[i], l.entities[i]))\n",
    "    outputs.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'food_url': 'https://www.allrecipes.com/recipe/15253/chocolate-snowballs/',\n",
       " 'type_url': 'https://www.allrecipes.com/recipes/841/holidays-and-events/christmas/desserts/christmas-cookies/',\n",
       " 'type_name': 'Christmas Cookies',\n",
       " 'food_name': 'Chocolate Snowballs',\n",
       " 'food_ingredients': ['1 1/4 cups butter',\n",
       "  '2/3 cup white sugar',\n",
       "  '1 teaspoon vanilla extract',\n",
       "  '2 cups all-purpose flour',\n",
       "  '1/8 teaspoon salt',\n",
       "  '1/2 cup unsweetened cocoa powder',\n",
       "  '2 cups chopped pecans',\n",
       "  \"1/2 cup confectioners' sugar for decoration\"],\n",
       " 'extraction_results': [(1.25, 'cup', 'butter'),\n",
       "  (0.6666666666666666, 'cup', 'white sugar'),\n",
       "  (1.0, 'teaspoon', 'vanilla extract'),\n",
       "  (2.0, 'cup', 'purpose flour'),\n",
       "  (0.125, 'teaspoon', 'salt'),\n",
       "  (0.5, 'cup', 'unsweetened cocoa powder'),\n",
       "  (2.0, 'cup', 'chop pecan'),\n",
       "  (0.5, 'DEFAULT', 'cup confectioner sugar decoration')]}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"recipe_extraction.json\", \"w\") as j:\n",
    "    json.dump(outputs, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3]",
   "language": "python",
   "name": "conda-env-miniconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
